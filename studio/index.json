{
  "count": 22,
  "files": [
    {
      "description": "## Age of Empires 2 Replays\n\n\nDerived from https://www.reddit.com/r/aoe2/comments/xj815r/aoepulse_database_dump_100_gb_5_million_games/",
      "engine": "bigquery",
      "filename": "age_of_empires_2.json",
      "name": "age_of_empires_2",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "# Chicago Crime Data",
      "engine": "bigquery",
      "filename": "chicago_crime.json",
      "name": "chicago_crime",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "### WIP Crypto Dataset",
      "engine": "bigquery",
      "filename": "crypto.json",
      "name": "crypto",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "The demo model used in Studio tutorials",
      "engine": "duckdb",
      "filename": "demo-model.json",
      "name": "demo-model",
      "tags": [
        "duckdb",
        "benchmark",
        "demo"
      ]
    },
    {
      "description": "## FAA Data - 2000 - 2005\n\nFor DuckDB. Parquet files. USA only. Normalized and contains high level flight, carrier, aircraft, model, and airport information.",
      "engine": "duckdb",
      "filename": "faa.json",
      "name": "faa",
      "tags": [
        "duckdb"
      ]
    },
    {
      "description": "fcc_political_ads dataset for bigquery",
      "engine": "bigquery",
      "filename": "fcc_political_ads.json",
      "name": "fcc_political_ads",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "# Github Data\n\nContext in this [blog post](https://cloud.google.com/blog/topics/public-datasets/github-on-bigquery-analyze-all-the-open-source-code)",
      "engine": "bigquery",
      "filename": "github.json",
      "name": "github",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "# Google Search Trends\n\nDaily top 25 terms in the United States with score, ranking, time, and designated market area (DMA) code.\n\nHistorical data only includes terms that are in the current trending dataset; focus on analysis of the\nlast 30 days.",
      "engine": "bigquery",
      "filename": "google_search_trends.json",
      "name": "google_search_trends",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "# Bigquery Hackernews Dataset\n\nUp to date.",
      "engine": "bigquery",
      "filename": "hacker_news.json",
      "name": "hacker_news",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "iris_data dataset for duckdb",
      "engine": "duckdb",
      "filename": "iris_data.json",
      "name": "iris_data",
      "tags": [
        "duckdb"
      ]
    },
    {
      "description": "## The Marine Organismal Body Size (MOBS) Database\n\nA dataset of marine animals, sizes, and metadata.\n\nMcClain, C. R., Heim, N. A., Knope, M. L., Monarrez, P. M., Payne, J. L., Santos, I. T., & Webb, T. J. (2025). MOBS 1.0: A database of interspecific variation in marine organismal body sizes. Global Ecology and Biogeography, 34: e70062. https://doi.org/10.1111/geb.70062\n\n\nWikipedia for descriptions and images.",
      "engine": "duckdb",
      "filename": "mobs.json",
      "name": "mobs",
      "tags": [
        "duckdb"
      ]
    },
    {
      "description": "# NCAA Basketball Dataset\n\n\n\n## Examples\nThis example shows some basic NCAA Men's Basketball game analysis, using the public\nBigquery datasets, equivalent to [this lab](https://www.cloudskillsboost.google/focuses/624?parent=catalog)\n\n\n## Find out which events happen most often?\n\nLab\n```sql\n#standardSQL\nSELECT\n  event_type,\n  COUNT(*) AS event_count\nFROM `bigquery-public-data.ncaa_basketball.mbb_pbp_sr`\nGROUP BY 1\nORDER BY event_count DESC;\n```\n\nPreql\n```sql  \nselect \n    game_event.type,\n    game_event.count\norder by \ngame_event.count\n    desc;\n```\n\n### Games with the most 3 points made?\n\nLab\n```sql\n#standardSQL\n#most three points made\nSELECT\n  scheduled_date,\n  name,\n  market,\n  alias,\n  three_points_att,\n  three_points_made,\n  three_points_pct,\n  opp_name,\n  opp_market,\n  opp_alias,\n  opp_three_points_att,\n  opp_three_points_made,\n  opp_three_points_pct,\n  (three_points_made + opp_three_points_made) AS total_threes\nFROM `bigquery-public-data.ncaa_basketball.mbb_teams_games_sr`\nWHERE season > 2010\nORDER BY total_threes DESC\nLIMIT 5;\n\n```\n\n\nPreQL\n```sql\n\n\nSELECT\n  game.id,\n  game.scheduled_date,\n  game.season,\n  game.home_team.name,\n  game.home_market,\n  game.home_alias,\n  game.home_three_points_att,\n  game.home_three_points_made,\n  game.home_three_points_pct,\n  game.away_team.name,\n  game.away_market,\n  game.away_alias,\n  game.away_three_points_att,\n  game.away_three_points_made,\n  game.away_three_points_pct,\n  game.total_three_points_made\nwhere game.season > 2010\n\nORDER BY \n    game.total_three_points_made desc\nLIMIT 5\n;\n\n```",
      "engine": "bigquery",
      "filename": "ncaa_basketball.json",
      "name": "ncaa_basketball",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "# NYC Citibike Dataset\n\n\n\n## Examples\nThis example walks through an [existing analysis](https://fitriwidyan.medium.com/nyc-citi-bike-trips-data-analysis-a07a1db9c1be) of New York Citibike usage, \nbut writes out the queries in trilogy. The full code can be found in the script.preql\nsection in this folder.\n\nFor this kind of one-off analysis, the queries should look quite similar. Note that the\ntrilogy examples are intended to be run sequentially as they define a few concepts\nthat are re-used in later queries. \n\n\n## Comparisons\n\n### Basic Select\nThe first query counts bikes in the system by year.\n\nSQL:\n```sql\nSELECT \n    EXTRACT(YEAR FROM starttime) AS year, \n    COUNT(DISTINCT(bikeid)) AS num_bikes\nFROM `bigquery-public-data.new_york_citibike.citibike_trips`\nGROUP BY year\nORDER BY year;\n```\n\nIn preql, we already have a bike.count metric defined in the public model, \nso we'll reference that and derive the year from the start time.\nThese queries are similar. \n\nPreQL:\n```sql\nproperty `trip.year<-year(trip.start_time)`;\n\nSELECT\n\ttrip.year,\n\tbike.count\nORDER BY\n    trip.year asc\nlimit 100;\n```\n\n### Case Statement\n\nNext we'll look at travel by 'generation'. Since we haven't implemented trilogy case/switch statements yet,\nthis gets a bit hacky.\n\n```sql\nWITH new_view AS(\n SELECT birth_year,\n CASE WHEN birth_year BETWEEN 1883 AND 1900 THEN \u2018Lost Generation\u2019\n      WHEN birth_year BETWEEN 1901 AND 1927 THEN \u2018G.I. Generation\u2019\n      WHEN birth_year BETWEEN 1928 AND 1945 THEN \u2018Silent Generation\u2019         \n      WHEN birth_year BETWEEN 1946 AND 1964 THEN \u2018Baby Boomers\u2019\n      WHEN birth_year BETWEEN 1965 AND 1980 THEN \u2018Generation X\u2019\n      WHEN birth_year BETWEEN 1981 AND 1996 THEN \u2018Millenials'         \n      WHEN birth_year BETWEEN 1997 AND 2012 THEN \u2018Generation Z' \n      ELSE 'Other'\n    END AS generation\n  FROM `bigquery-public-data.new_york_citibike.citibike_trips`)\nSELECT COUNT(birth_year) AS users, generation\nFROM new_view\nGROUP BY generation\nORDER BY users DESC;\n```\n\nIn trilogy we'll define a new property of the birth year for the generation,\nthen provide a datasource off a query as our source.\n```preql\nproperty trip.rider.birth_year.generation string;\n\ndatasource generations (\n    birth_year:trip.rider.birth_year,\n    CASE WHEN birth_year BETWEEN 1883 AND 1900 THEN 'Lost Generation'\n      WHEN birth_year BETWEEN 1901 AND 1927 THEN 'G.I. Generation'\n      WHEN birth_year BETWEEN 1928 AND 1945 THEN 'Silent Generation'\n      WHEN birth_year BETWEEN 1946 AND 1964 THEN 'Baby Boomers'\n      WHEN birth_year BETWEEN 1965 AND 1980 THEN 'Generation X'\n      WHEN birth_year BETWEEN 1981 AND 1996 THEN 'Millenials'\n      WHEN birth_year BETWEEN 1997 AND 2012 THEN 'Generation Z'\n      ELSE 'other'\n      END: generation\n    )\ngrain()\naddress `bigquery-public-data.new_york_citibike.citibike_trips`;\n\nselect\n    generation,\n    trip.count\norder by\n    trip.count desc;\n```\n\n### Stations by 2016 trips\n\nThis sql find the number of rides that started from given stations\nby a subscriber in 2016.\n\n```sql\nSELECT start_station_name, num_station\nFROM \n  (SELECT start_station_name, COUNT(start_station_name) AS       \n   num_station, EXTRACT(YEAR FROM starttime) AS year\n   FROM `bigquery-public-data.new_york_citibike.citibike_trips`\n   WHERE usertype = 'Subscriber'\n   GROUP BY start_station_name,year\n   ORDER BY year)\nWHERE year = 2016\nORDER BY num_station DESC\nLIMIT 10\n```\n\n\nIn preql, we'll reuse the year we already defined, filter to trips in that year\nwhere the type were subscriber, count those, and provide trip.start_station_name\nin the output to aggregate to that level. \n```sql\nkey subscriber_rides_2016 <- filter trip.start_time where trip.year=2016 and trip.user_type='Subscriber';\n\nmetric subscriber_ride_count_2016 <- count(subscriber_rides_2016);\n\nselect\n    trip.start_station_name,\n    subscriber_ride_count_2016,\norder by\n    subscriber_ride_count_2016 desc\nlimit 10;\n\n```\n\n\n### Bike Stats\n\n\n```sql\nSELECT bikeid, num_trip, duration, ROUND((duration/num_trip), 2) AS avg_duration_trip\nFROM\n    (SELECT bikeid, SUM(tripduration) AS duration, COUNT(*) AS    \n     num_trip\n     FROM `bigquery-public-data.new_york_citibike.citibike_trips`\n     WHERE bikeid IS NOT NULL\n     GROUP BY bikeid\n     ORDER BY duration DESC)\nLIMIT 10;\n```\n\nWe have a few of these defined in our public model, so the only additional\none is average trip duration. Then this is a striaghtforward select -\nno nesting required.\n```preql\nmetric trip.avg_duration <- trip.total_duration / trip.count;\n\nselect\n    bike.id,\n    trip.count,\n    trip.total_duration,\n    trip.avg_duration,\norder by\n    trip.total_duration desc\nlimit 10;\n```\n\n### Rides by Gender\n\nRides by gender is straightforward in SQL.\n```sql\nSELECT EXTRACT(YEAR FROM starttime) AS year,\n       COUNT(CASE WHEN gender = \u2018female\u2019 THEN 1 END ) AS \n       count_female,\n       COUNT(CASE WHEN gender = \u2018male\u2019 THEN 1 END ) AS count_male\nFROM `bigquery-public-data.new_york_citibike.citibike_trips`\nGROUP BY year\nORDER BY year;\n```\n\nWe'll highlight two strategies to answer this.\nWe can either define a generic aggregation - male_trips - that can be created at any grain,\nor define a property of year that is the output of aggregating to that level in a query.\n\nFor this query, those produce identical outcomes - but if you reuse the concepts later \non you\n```preql\nproperty male_trip  <- filter trip.start_time where rider.gender = 'male';\nproperty female_trip <- filter trip.start_time where rider.gender = 'female';\n\n# we can either define an arbitrary grain metric here, that can be aggregated\n# to any possible grain later (like trip.month)\nmetric male_trips <- count(male_trip);\nmetric female_trips <- count(female_trip);\n\n# or create a new property of the year implicitly via a select query. \n\nselect\n    trip.year,\n    count(male_trip)-> yearly_male_trips,\n    count(female_trip) -> yearly_female_trips\norder by\n    trip.year\n    asc;\n\nproperty trip.month <- month(trip.start_time);\n\nselect\n    trip.year,\n    trip.month,\n    male_trips,\n    female_trips,\n    male_trips / yearly_male_trips -> percent_of_yearly_total_male_trips,\n    female_trips /yearly_female_trips -> percent_of_yearly_total_female_trips\n  \nwhere trip.year = 2018\norder by trip.month desc;\n```\n\n## Subscriber\n\nSubscriber query is straightforward.\n\n```sql\nSELECT EXTRACT(YEAR FROM starttime) AS year,\n       COUNT(CASE WHEN usertype = \u2018Subscriber\u2019 THEN 1 END ) AS\n       count_subscriber,\n       COUNT(CASE WHEN usertype = \u2018Customer\u2019 THEN 1 END ) AS    \n       count_customer\nFROM `bigquery-public-data.new_york_citibike.citibike_trips`\nGROUP BY year\nORDER BY year;\n```\n\n\n```sql\n\nproperty subscriber_trip <- filter trip.start_time where trip.user_type = 'Subscriber';\nproperty customer_trip <- filter trip.start_time where trip.user_type = 'Customer';\n\nselect \n    trip.year,\n    count(trip.start_time) -> yearly_trips,\n    count(subscriber_trip) -> yearly_subscriber_trips,\n    count(customer_trip) -> yearly_customer_trips\norder by \n    trip.year asc;\n   \n```\n\n\n## Trip Growth\n\nCalculating trip growth shows how to use window functions, such as lag/lead. \n\n```sql\nSELECT year, trip, previous, trip-previous AS trip_growth, \n       ROUND((trip-previous)/previous*100, 2) AS \n       percentage_trip_growth\nFROM (SELECT year, trip, LAG(trip) OVER (ORDER BY year) AS previous\n  FROM (SELECT EXTRACT(YEAR FROM starttime) AS year,\n        COUNT(start_station_id) AS trip\n        FROM `bigquery-public-data.new_york_citibike.citibike_trips`\n        GROUP BY year)\n  WHERE year IS NOT NULL\n  GROUP BY year, trip\n  ORDER BY year)\nORDER BY year\n\n\n```\n\n\n```sql\nmetric lagging_yearly_trips <- lag yearly_trips by trip.year asc;\nmetric yoy_trip_growth <- yearly_trips - lagging_yearly_trips;\nmetric yoy_growth_ratio <- round(yoy_trip_growth / lagging_yearly_trips * 100 ,2);\n\nselect\n    trip.year,\n    yearly_trips,\n    lagging_yearly_trips,\n    yoy_trip_growth,\n    yoy_growth_ratio\norder by \n    trip.year asc;\n```",
      "engine": "bigquery",
      "filename": "new_york_citibike.json",
      "name": "new_york_citibike",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "norway_transit dataset for bigquery",
      "engine": "bigquery",
      "filename": "norway_transit.json",
      "name": "norway_transit",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "open_street_map dataset for bigquery",
      "engine": "bigquery",
      "filename": "open_street_map.json",
      "name": "open_street_map",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "## Stack Overflow Data\n\nContext in this [blog post](https://cloud.google.com/blog/topics/public-datasets/google-bigquery-public-datasets-now-include-stack-overflow-q-a)",
      "engine": "bigquery",
      "filename": "stack_overflow.json",
      "name": "stack_overflow",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "tasty_bytes dataset for snowflake",
      "engine": "snowflake",
      "filename": "tasty_bytes.json",
      "name": "tasty_bytes",
      "tags": [
        "snowflake"
      ]
    },
    {
      "description": "thelook_ecommerce dataset for bigquery",
      "engine": "bigquery",
      "filename": "thelook_ecommerce.json",
      "name": "thelook_ecommerce",
      "tags": [
        "bigquery"
      ]
    },
    {
      "description": "### Titanic Dataset\n\nDataset from demo. use 'setup_environment.py' to build an executor with the csv files imported.",
      "engine": "duckdb",
      "filename": "titanic.json",
      "name": "titanic",
      "tags": [
        "duckdb"
      ]
    },
    {
      "description": "## TPC-DS dataset\n\nUsable with the [duckdb extension](https://duckdb.org/docs/extensions/tpcds.html).\n\nRequires generating data first.\n\nTrilogy:\n```sql\n# intialize the TPC-DS schema\nRAW_SQL('''\nINSTALL tpcds;\nLOAD tpcds;\nSELECT * FROM dsdgen(sf=.25);\n''');\n\nSQL:\n```\nScale factor 1 example:\n```sql\nINSTALL tpcds;\nLOAD tpcds;\nCALL dsdgen(sf = 1);\n```",
      "engine": "duckdb",
      "filename": "tpc_ds.json",
      "name": "tpc_ds",
      "tags": [
        "duckdb",
        "benchmark"
      ]
    },
    {
      "description": "## TPC-H dataset\n\nUses duck-db hosted parquet files.",
      "engine": "duckdb",
      "filename": "tpc_h.json",
      "name": "tpc_h",
      "tags": [
        "duckdb",
        "benchmark"
      ]
    },
    {
      "description": "# Name/Birth Dataset",
      "engine": "bigquery",
      "filename": "usa_names.json",
      "name": "usa_names",
      "tags": [
        "bigquery"
      ]
    }
  ],
  "updated_at": "2025-08-02T10:50:04.708255"
}